{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic TensorFlow 2.0 Example \n",
    "\n",
    "#### by Sooyeon Won \n",
    "In this notebook I recreated the previous machine learning algorithm using TensorFlow 2.0.\n",
    "\n",
    "### Keywords \n",
    "- TensorFlow 2.0\n",
    "- Simple Linear Regression\n",
    "\n",
    "\n",
    "\n",
    "### Contents \n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#libraries\">1.  Import the relevant libraries</a></li>\n",
    "<li><a href=\"#Generate\">2.  Generate data</a></li>\n",
    "<li><a href=\"#Solve\">3.  Build a model with TensorFlow</a></li>\n",
    "<li><a href=\"#Extract1\">4.  Extract the weights and bias</a></li>\n",
    "<li><a href=\"#Extract2\">5.  Extract the outputs (make predictions)</a></li>\n",
    "<li><a href=\"#Plot\">6.  Plot the data</a></li>\n",
    "\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='libraries'></a>\n",
    "## 1. Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Generate'></a>\n",
    "## 2. Data generation\n",
    "\n",
    "I generated data using the identical logic and code as the basic NN example from the [previous notebook](https://github.com/SooyeonWon/real_world_projects_collection_DS2020/blob/main/02_Basic_Neural_Network_SLR.ipynb). The only difference now is that we save it to an **npz file**. Npz is numpy's file type which allows you to save numpy arrays into a single .npz file. \n",
    "\n",
    "The concept of npz file is useful in machine learning cases, since the format of given datas is often csv, database, etc. Also, these formats are preprocessed into a desired format.\n",
    "\n",
    "Thus, I saved it into  npz files to build algorithm using the npz files, not using the original file. So basically, I save the NumPy arrays into a file that I can later access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the size of training data\n",
    "observations = 1000\n",
    "\n",
    "# Generate 2 input variables: xs, zs\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n",
    "zs = np.random.uniform(-10, 10, (observations,1))\n",
    "\n",
    "# Combine the 2 input vectors into one matrix (1000 x 2)\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "\n",
    "# Generate a random noise \n",
    "noise = np.random.uniform(-1, 1, (observations,1))\n",
    "\n",
    "# Produce the target according to the above defined noise. \n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "# Save into an npz file called \"TF_intro\"\n",
    "np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Comments:** \n",
    ">- Firstly, I declared a variable ('observations'), which indicates the size of the training set that I want to generate. For this basic example, I generated 2 input variable, and named xs, xz. The variables are generated randomly and uniformly distributed. So, you can understand that the size of xs and zs is a vector of 1000(observations) x 1. \n",
    ">- Then I stacked the two dimensions (i.e. the input vectors) into one input matrix, using numpy method. \n",
    ">- Since I want to \"make up\" a function, use the ML methodology, and see if the algorithm has learned it, so I generate a small random noise to the function.\n",
    ">        f(x,z) = 2x - 3z + 5 + noise.\n",
    ">-Then I produced the \"artifical\" targets according to the f(x,z) definition. In this way, we can consider that the weights should be 2 and -3, while the bias is 5.\n",
    ">- Finally, I save the NumPy array into an npz file called \"TF_intro\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Solve'></a>\n",
    "## 3. Build a Model  with TensorFlow\n",
    "\n",
    "<i/>Note: This intro is just the basics of TensorFlow which has way more capabilities and depth than that.<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the NPZ\n",
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of inputs and outputs \n",
    "# I set 2 input variables \n",
    "input_size = 2 \n",
    "\n",
    "# I set 1 output variable.\n",
    "output_size = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** I declared the two variables where I assigned the input/output size of the model. It should be equal to the number of input/ output variables that I previously set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Build the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([                            \n",
    "                            # List each layer in the model using \"Dense\" method\n",
    "                            tf.keras.layers.Dense(output_size,\n",
    "                                                 kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1),\n",
    "                                                 bias_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n",
    "                                                 )\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** \n",
    ">- Note that I must build the model, to employ a Tensorflow. TF2 is based on Keras, so that is the module needed to build a model. 'Sequential' is the function that we lay down the model. \n",
    ">- In TF2, no calculations are involved, I just described the network. Each 'layer' is listed in the model. \n",
    ">- The method 'Dense' indicates, our mathematical operation to be (xw + b).\n",
    ">- For this analysis, I include the basic arguments to create a solution that is as close as possible to the previous NumPy model. However there are many more extra arguments to customize your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Set the Optimization Algorithm: SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** \n",
    ">- We should also define a custom optimizer, where I can specify the learning rate. For this analysis, I set a stochastic gradient descent (SGD) as the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Design the Objective Function: 'compile' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** \n",
    ">- 'compile' is the place where I can select and indicate the optimizers and the loss. \n",
    ">- L2-norm loss : Least sum of squared error\n",
    ">- Scaling by # of observations : mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 - 0s - loss: 21.6009\n",
      "Epoch 2/100\n",
      "32/32 - 0s - loss: 1.3738\n",
      "Epoch 3/100\n",
      "32/32 - 0s - loss: 0.4047\n",
      "Epoch 4/100\n",
      "32/32 - 0s - loss: 0.3855\n",
      "Epoch 5/100\n",
      "32/32 - 0s - loss: 0.3533\n",
      "Epoch 6/100\n",
      "32/32 - 0s - loss: 0.3854\n",
      "Epoch 7/100\n",
      "32/32 - 0s - loss: 0.3627\n",
      "Epoch 8/100\n",
      "32/32 - 0s - loss: 0.3615\n",
      "Epoch 9/100\n",
      "32/32 - 0s - loss: 0.3686\n",
      "Epoch 10/100\n",
      "32/32 - 0s - loss: 0.3940\n",
      "Epoch 11/100\n",
      "32/32 - 0s - loss: 0.3594\n",
      "Epoch 12/100\n",
      "32/32 - 0s - loss: 0.3542\n",
      "Epoch 13/100\n",
      "32/32 - 0s - loss: 0.3983\n",
      "Epoch 14/100\n",
      "32/32 - 0s - loss: 0.3647\n",
      "Epoch 15/100\n",
      "32/32 - 0s - loss: 0.3439\n",
      "Epoch 16/100\n",
      "32/32 - 0s - loss: 0.3595\n",
      "Epoch 17/100\n",
      "32/32 - 0s - loss: 0.3524\n",
      "Epoch 18/100\n",
      "32/32 - 0s - loss: 0.3671\n",
      "Epoch 19/100\n",
      "32/32 - 0s - loss: 0.3430\n",
      "Epoch 20/100\n",
      "32/32 - 0s - loss: 0.3828\n",
      "Epoch 21/100\n",
      "32/32 - 0s - loss: 0.3607\n",
      "Epoch 22/100\n",
      "32/32 - 0s - loss: 0.3609\n",
      "Epoch 23/100\n",
      "32/32 - 0s - loss: 0.3523\n",
      "Epoch 24/100\n",
      "32/32 - 0s - loss: 0.3630\n",
      "Epoch 25/100\n",
      "32/32 - 0s - loss: 0.3559\n",
      "Epoch 26/100\n",
      "32/32 - 0s - loss: 0.3433\n",
      "Epoch 27/100\n",
      "32/32 - 0s - loss: 0.3505\n",
      "Epoch 28/100\n",
      "32/32 - 0s - loss: 0.3495\n",
      "Epoch 29/100\n",
      "32/32 - 0s - loss: 0.3745\n",
      "Epoch 30/100\n",
      "32/32 - 0s - loss: 0.3888\n",
      "Epoch 31/100\n",
      "32/32 - 0s - loss: 0.3456\n",
      "Epoch 32/100\n",
      "32/32 - 0s - loss: 0.3458\n",
      "Epoch 33/100\n",
      "32/32 - 0s - loss: 0.3631\n",
      "Epoch 34/100\n",
      "32/32 - 0s - loss: 0.4236\n",
      "Epoch 35/100\n",
      "32/32 - 0s - loss: 0.3649\n",
      "Epoch 36/100\n",
      "32/32 - 0s - loss: 0.3652\n",
      "Epoch 37/100\n",
      "32/32 - 0s - loss: 0.3628\n",
      "Epoch 38/100\n",
      "32/32 - 0s - loss: 0.3485\n",
      "Epoch 39/100\n",
      "32/32 - 0s - loss: 0.3652\n",
      "Epoch 40/100\n",
      "32/32 - 0s - loss: 0.3574\n",
      "Epoch 41/100\n",
      "32/32 - 0s - loss: 0.3774\n",
      "Epoch 42/100\n",
      "32/32 - 0s - loss: 0.3464\n",
      "Epoch 43/100\n",
      "32/32 - 0s - loss: 0.3522\n",
      "Epoch 44/100\n",
      "32/32 - 0s - loss: 0.3556\n",
      "Epoch 45/100\n",
      "32/32 - 0s - loss: 0.3405\n",
      "Epoch 46/100\n",
      "32/32 - 0s - loss: 0.3446\n",
      "Epoch 47/100\n",
      "32/32 - 0s - loss: 0.3994\n",
      "Epoch 48/100\n",
      "32/32 - 0s - loss: 0.3998\n",
      "Epoch 49/100\n",
      "32/32 - 0s - loss: 0.3500\n",
      "Epoch 50/100\n",
      "32/32 - 0s - loss: 0.3619\n",
      "Epoch 51/100\n",
      "32/32 - 0s - loss: 0.4269\n",
      "Epoch 52/100\n",
      "32/32 - 0s - loss: 0.3474\n",
      "Epoch 53/100\n",
      "32/32 - 0s - loss: 0.3460\n",
      "Epoch 54/100\n",
      "32/32 - 0s - loss: 0.3623\n",
      "Epoch 55/100\n",
      "32/32 - 0s - loss: 0.3369\n",
      "Epoch 56/100\n",
      "32/32 - 0s - loss: 0.3518\n",
      "Epoch 57/100\n",
      "32/32 - 0s - loss: 0.3599\n",
      "Epoch 58/100\n",
      "32/32 - 0s - loss: 0.3530\n",
      "Epoch 59/100\n",
      "32/32 - 0s - loss: 0.4084\n",
      "Epoch 60/100\n",
      "32/32 - 0s - loss: 0.3706\n",
      "Epoch 61/100\n",
      "32/32 - 0s - loss: 0.3825\n",
      "Epoch 62/100\n",
      "32/32 - 0s - loss: 0.3512\n",
      "Epoch 63/100\n",
      "32/32 - 0s - loss: 0.3561\n",
      "Epoch 64/100\n",
      "32/32 - 0s - loss: 0.3655\n",
      "Epoch 65/100\n",
      "32/32 - 0s - loss: 0.3482\n",
      "Epoch 66/100\n",
      "32/32 - 0s - loss: 0.3590\n",
      "Epoch 67/100\n",
      "32/32 - 0s - loss: 0.3610\n",
      "Epoch 68/100\n",
      "32/32 - 0s - loss: 0.3709\n",
      "Epoch 69/100\n",
      "32/32 - 0s - loss: 0.4205\n",
      "Epoch 70/100\n",
      "32/32 - 0s - loss: 0.3816\n",
      "Epoch 71/100\n",
      "32/32 - 0s - loss: 0.3554\n",
      "Epoch 72/100\n",
      "32/32 - 0s - loss: 0.3824\n",
      "Epoch 73/100\n",
      "32/32 - 0s - loss: 0.3491\n",
      "Epoch 74/100\n",
      "32/32 - 0s - loss: 0.3594\n",
      "Epoch 75/100\n",
      "32/32 - 0s - loss: 0.4019\n",
      "Epoch 76/100\n",
      "32/32 - 0s - loss: 0.3367\n",
      "Epoch 77/100\n",
      "32/32 - 0s - loss: 0.3531\n",
      "Epoch 78/100\n",
      "32/32 - 0s - loss: 0.3556\n",
      "Epoch 79/100\n",
      "32/32 - 0s - loss: 0.3562\n",
      "Epoch 80/100\n",
      "32/32 - 0s - loss: 0.3696\n",
      "Epoch 81/100\n",
      "32/32 - 0s - loss: 0.3551\n",
      "Epoch 82/100\n",
      "32/32 - 0s - loss: 0.3359\n",
      "Epoch 83/100\n",
      "32/32 - 0s - loss: 0.3608\n",
      "Epoch 84/100\n",
      "32/32 - 0s - loss: 0.3627\n",
      "Epoch 85/100\n",
      "32/32 - 0s - loss: 0.3695\n",
      "Epoch 86/100\n",
      "32/32 - 0s - loss: 0.3371\n",
      "Epoch 87/100\n",
      "32/32 - 0s - loss: 0.3700\n",
      "Epoch 88/100\n",
      "32/32 - 0s - loss: 0.3424\n",
      "Epoch 89/100\n",
      "32/32 - 0s - loss: 0.3452\n",
      "Epoch 90/100\n",
      "32/32 - 0s - loss: 0.3517\n",
      "Epoch 91/100\n",
      "32/32 - 0s - loss: 0.3502\n",
      "Epoch 92/100\n",
      "32/32 - 0s - loss: 0.3537\n",
      "Epoch 93/100\n",
      "32/32 - 0s - loss: 0.3659\n",
      "Epoch 94/100\n",
      "32/32 - 0s - loss: 0.3448\n",
      "Epoch 95/100\n",
      "32/32 - 0s - loss: 0.3626\n",
      "Epoch 96/100\n",
      "32/32 - 0s - loss: 0.3532\n",
      "Epoch 97/100\n",
      "32/32 - 0s - loss: 0.3552\n",
      "Epoch 98/100\n",
      "32/32 - 0s - loss: 0.3591\n",
      "Epoch 99/100\n",
      "32/32 - 0s - loss: 0.3510\n",
      "Epoch 100/100\n",
      "32/32 - 0s - loss: 0.3594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29095316dc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Comments:** \n",
    ">- Finally, I fit the model, by specifying the inputs and targets. if they are not otherwise specified the number of epochs (= iterations over the full dataset) will be 1 (a single epoch of training), so the number of epochs is 'kind of' mandatory, too. \n",
    ">- I prefer verbose=2 (meaning, one line per epochs) to verbose =1 (meaning, progress bar), or verbose =0 (meaning, silent- no output about the training is displayed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Extract1'></a>\n",
    "## 4. Extract the weights and bias\n",
    "Extracting the weight(s) and bias(es) of a model is not an essential step for the machine learning process. In fact, usually they would not tell much in a deep learning context. However, this simple example was set up to verify if the answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.0166128],\n",
       "        [-2.9801621]], dtype=float32),\n",
       " array([4.9958825], dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I saved the weights and biases in separate variables for easier examination\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Extract2'></a>\n",
    "## 5. Extract the outputs (make predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_target = model.predict_on_batch(training_data['inputs']).round(1)\n",
    "actual_target = training_data['targets'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** I predicted the target values in order to make use of the model. To make the values readable, I rounded the values. In practice, we predict the data using test dataset, which is not used for training. By displaying the actual targets (actual observed values), we can compare the outputs and the targets and evaluate how well the model works. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Plot'></a>\n",
    "## 6. Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Comments:** The model is now optimized, so the outputs are calculated based on the last form of the model. I used 'np.squeeze' the arrays in order to fit them to what the plot function expects. Note that the visualisation is exactly the same as in the previous notebook. Since this analysis is the very basic Tensorflow, it does not show  the point of TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
