{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Case Study: Absenteeism \n",
    "#### by Sooyeon Won \n",
    "\n",
    "### Part 2: Machine Learning \n",
    "\n",
    "### Keywords \n",
    "- Supervised Machine Learning \n",
    "- Classification Model\n",
    "- Logistic Regression \n",
    "\n",
    "\n",
    "### Contents \n",
    "\n",
    "<ul>    \n",
    "<li><a href=\"#Preprocessing\">1.  Data Preprocessing</a></li>\n",
    "<li><a href=\"#Analysis\">2.  Machine Learning</a></li>\n",
    "<li><a href=\"#Deployment\">3.  Model Deployment</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation from Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed data\n",
    "data_preprocessed = pd.read_csv('Absenteeism_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  Day of the Week  \\\n",
       "0         0         0         0         1            7                1   \n",
       "1         0         0         0         0            7                1   \n",
       "2         0         0         0         1            7                2   \n",
       "3         1         0         0         0            7                3   \n",
       "4         0         0         0         1            7                3   \n",
       "\n",
       "   Transportation Expense  Distance to Work  Age  Daily Work Load Average  \\\n",
       "0                     289                36   33                  239.554   \n",
       "1                     118                13   50                  239.554   \n",
       "2                     179                51   38                  239.554   \n",
       "3                     279                 5   39                  239.554   \n",
       "4                     289                36   33                  239.554   \n",
       "\n",
       "   Body Mass Index  Education  Children  Pet  Absenteeism Time in Hours  \n",
       "0               30          0         2    1                          4  \n",
       "1               31          0         1    0                          0  \n",
       "2               31          0         0    0                          2  \n",
       "3               24          0         2    0                          4  \n",
       "4               30          0         2    1                          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eyeball the data\n",
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Analysis'></a>\n",
    "### 2. Machine Learning \n",
    "- 2.1. Create the targets\n",
    "- 2.2. Select the inputs for the regression\n",
    "- 2.3. Standardize & Split the data\n",
    "- 2.4. Logistic regression with sklearn\n",
    "- 2.5. Training the Model\n",
    "- 2.6. Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 1. Create the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the median value for the cut-off line \n",
    "data_preprocessed['Absenteeism Time in Hours'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create targets using parameterized code\n",
    "targets = np.where(data_preprocessed['Absenteeism Time in Hours'] > \n",
    "                   data_preprocessed['Absenteeism Time in Hours'].median(), 1, 0)\n",
    "\n",
    "# Create a Series in the original dataframe\n",
    "data_preprocessed['Excessive Absenteeism'] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Day of the Week</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Distance to Work</th>\n",
       "      <th>Age</th>\n",
       "      <th>Daily Work Load Average</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Absenteeism Time in Hours</th>\n",
       "      <th>Excessive Absenteeism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>179</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>239.554</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>279</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>239.554</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>289</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>239.554</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  Day of the Week  \\\n",
       "0         0         0         0         1            7                1   \n",
       "1         0         0         0         0            7                1   \n",
       "2         0         0         0         1            7                2   \n",
       "3         1         0         0         0            7                3   \n",
       "4         0         0         0         1            7                3   \n",
       "\n",
       "   Transportation Expense  Distance to Work  Age  Daily Work Load Average  \\\n",
       "0                     289                36   33                  239.554   \n",
       "1                     118                13   50                  239.554   \n",
       "2                     179                51   38                  239.554   \n",
       "3                     279                 5   39                  239.554   \n",
       "4                     289                36   33                  239.554   \n",
       "\n",
       "   Body Mass Index  Education  Children  Pet  Absenteeism Time in Hours  \\\n",
       "0               30          0         2    1                          4   \n",
       "1               31          0         1    0                          0   \n",
       "2               31          0         0    0                          2   \n",
       "3               24          0         2    0                          4   \n",
       "4               30          0         2    1                          2   \n",
       "\n",
       "   Excessive Absenteeism  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the result of it\n",
    "data_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments**: In this section, I create the target variable for the regression.As in the dataset, the column of 'Absenteeism Time in Hours' is numeric. I basically classfied each data point (people) into classes by setting a cutoff line based on the median value of it. \n",
    "To do so, I found the median value of 'Absenteeism Time in Hours', which is 3 hours. Thus, if the value of 'Absenteeism Time in Hours' is larger than the median value, it is defined as one class of **'Excessively Absent (1)'**. On the other hand, if the values are smaller than or equal to the median value, the data points are classified as the class of **'Moderately Absent (0)'**. These are the values I aim for throughout this analysis. \n",
    "\n",
    "> The reason why the median value of the dataset is taken as as a cut-off line is that dataset will be balanced. In this way, there will be roughly equal number of 0s and 1s for the logistic regression. This is useful to balance the given data especially when the provided dataset is sufficiently enough. Note that .where() method is to assign 1 to anyone who has been absent 4 hours or more (more than 3 hours). This is the equivalent of taking half a day off.\n",
    "\n",
    "> Then I created a Series in the original data frame that will contain the targets for the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-check the Balanced Targets\n",
    "round(targets.sum() / targets.shape[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary variables\n",
    "data_with_targets = data_preprocessed.drop(['Absenteeism Time in Hours','Day of the Week',\n",
    "                                            'Daily Work Load Average','Distance to Work'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Excessive Absenteeism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>118</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>179</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>279</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>289</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0         0         0         0         1            7   \n",
       "1         0         0         0         0            7   \n",
       "2         0         0         0         1            7   \n",
       "3         1         0         0         0            7   \n",
       "4         0         0         0         1            7   \n",
       "\n",
       "   Transportation Expense  Age  Body Mass Index  Education  Children  Pet  \\\n",
       "0                     289   33               30          0         2    1   \n",
       "1                     118   50               31          0         1    0   \n",
       "2                     179   38               31          0         0    0   \n",
       "3                     279   39               24          0         2    0   \n",
       "4                     289   33               30          0         2    1   \n",
       "\n",
       "   Excessive Absenteeism  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eyeball the modified data \n",
    "data_with_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Comments:** \n",
    "After I classified the targets, I checked whether the dataset is balanced (what % of targets are 1s). \n",
    ">- targets.sum() implies the number of 1s in the targets \n",
    ">- shape[0] indicates the length of the targets array <br><br>\n",
    "> Then I created a checkpoint by dropping the unnecessary variables and the variables I 'eliminated' after exploring the weights. Finally I ended up with 700 samples with 12 variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 2.  Select the inputs for the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable that will contain the inputs (everything without the targets)\n",
    "unscaled_inputs = data_with_targets.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 3. Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Define scaler as an object\n",
    "absenteeism_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Standardization is one of the most common preprocessing tools. Since data of different magnitude (scale) can be biased towards high values, I want all inputs to be of similar magnitude. To do so, I used StandardScaler from sklearn library. Then I created a variable that contains the scaling information for this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomScaler(BaseEstimator,TransformerMixin): \n",
    "    \n",
    "    # init: to declare a CustomScaler object and what is calculated/declared\n",
    "    \n",
    "    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n",
    "        \n",
    "        # Scaler is nothing but a Standard Scaler object\n",
    "        self.scaler = StandardScaler(copy,with_mean,with_std)\n",
    "        # with some columns 'twist'\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "        \n",
    "    \n",
    "    # Method 1: fit, based on StandardScale\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    # Method 2: transform, conducting the actual scaling\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \n",
    "        # Record the initial order of the columns\n",
    "        init_col_order = X.columns\n",
    "        \n",
    "        # Scale all features, when creating the instance of the class\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        \n",
    "        # Declare a variable containing all information that was not scaled\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        \n",
    "        # Return a dataframe which contains all scaled features and all 'not scaled' features\n",
    "        # Use the original order recorded in the beginning\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4', 'Month Value',\n",
       "       'Transportation Expense', 'Age', 'Body Mass Index', 'Education',\n",
       "       'Children', 'Pet'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All columns \n",
    "unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns to omit\n",
    "columns_to_omit = ['Reason_1', 'Reason_2', 'Reason_3', 'Reason_4','Education']\n",
    "\n",
    "# Choose the columns to scale\n",
    "columns_to_scale = [x for x in unscaled_inputs.columns.values if x not in columns_to_omit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wonso\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass copy=True, with_mean=True, with_std=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Declare a scaler object, specifying the columns you want to scale\n",
    "absenteeism_scaler = CustomScaler(columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wonso\\anaconda3\\lib\\site-packages\\sklearn\\base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomScaler(columns=['Month Value', 'Transportation Expense', 'Age',\n",
       "                      'Body Mass Index', 'Children', 'Pet'],\n",
       "             copy=None, with_mean=None, with_std=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data, meaning calculate mean and standard deviation. \n",
    "# The information will be automatically stored inside the object. \n",
    "absenteeism_scaler.fit(unscaled_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reason_1</th>\n",
       "      <th>Reason_2</th>\n",
       "      <th>Reason_3</th>\n",
       "      <th>Reason_4</th>\n",
       "      <th>Month Value</th>\n",
       "      <th>Transportation Expense</th>\n",
       "      <th>Age</th>\n",
       "      <th>Body Mass Index</th>\n",
       "      <th>Education</th>\n",
       "      <th>Children</th>\n",
       "      <th>Pet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>-1.574681</td>\n",
       "      <td>2.130803</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.248310</td>\n",
       "      <td>1.002633</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>0.854936</td>\n",
       "      <td>0.405184</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>1.005844</td>\n",
       "      <td>-0.536062</td>\n",
       "      <td>0.767431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.568019</td>\n",
       "      <td>-0.654143</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>-1.114186</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880469</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.568019</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>-0.643782</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>1.126663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.568019</td>\n",
       "      <td>1.624567</td>\n",
       "      <td>-1.320435</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.568019</td>\n",
       "      <td>0.190942</td>\n",
       "      <td>-0.692937</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.919030</td>\n",
       "      <td>-0.589690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.568019</td>\n",
       "      <td>1.036026</td>\n",
       "      <td>0.562059</td>\n",
       "      <td>-0.408580</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019280</td>\n",
       "      <td>0.268487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reason_1  Reason_2  Reason_3  Reason_4  Month Value  \\\n",
       "0           0         0         0         1     0.030796   \n",
       "1           0         0         0         0     0.030796   \n",
       "2           0         0         0         1     0.030796   \n",
       "3           1         0         0         0     0.030796   \n",
       "4           0         0         0         1     0.030796   \n",
       "..        ...       ...       ...       ...          ...   \n",
       "695         1         0         0         0    -0.568019   \n",
       "696         1         0         0         0    -0.568019   \n",
       "697         1         0         0         0    -0.568019   \n",
       "698         0         0         0         1    -0.568019   \n",
       "699         0         0         0         1    -0.568019   \n",
       "\n",
       "     Transportation Expense       Age  Body Mass Index  Education  Children  \\\n",
       "0                  1.005844 -0.536062         0.767431          0  0.880469   \n",
       "1                 -1.574681  2.130803         1.002633          0 -0.019280   \n",
       "2                 -0.654143  0.248310         1.002633          0 -0.919030   \n",
       "3                  0.854936  0.405184        -0.643782          0  0.880469   \n",
       "4                  1.005844 -0.536062         0.767431          0  0.880469   \n",
       "..                      ...       ...              ...        ...       ...   \n",
       "695               -0.654143  0.562059        -1.114186          1  0.880469   \n",
       "696                0.040034 -1.320435        -0.643782          0 -0.019280   \n",
       "697                1.624567 -1.320435        -0.408580          1 -0.919030   \n",
       "698                0.190942 -0.692937        -0.408580          1 -0.919030   \n",
       "699                1.036026  0.562059        -0.408580          0 -0.019280   \n",
       "\n",
       "          Pet  \n",
       "0    0.268487  \n",
       "1   -0.589690  \n",
       "2   -0.589690  \n",
       "3   -0.589690  \n",
       "4    0.268487  \n",
       "..        ...  \n",
       "695 -0.589690  \n",
       "696  1.126663  \n",
       "697 -0.589690  \n",
       "698 -0.589690  \n",
       "699  0.268487  \n",
       "\n",
       "[700 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizes the data, using the transform method \n",
    "scaled_inputs = absenteeism_scaler.transform(unscaled_inputs)\n",
    "scaled_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> By fitting the data, I found the internal parameters of a model that will be used to transform data. \n",
    "Transforming applies these parameters to the data. The scaled_inputs are now an ndarray, because sklearn works with ndarrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train & test and shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inputs shape:  (560, 11) Train targets shape (560,)\n",
      "Test inputs shape:  (140, 11) Test targets shape (140,)\n"
     ]
    }
   ],
   "source": [
    "# Declare 4 variables for the split\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_inputs, targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Check the shape of the train inputs and targets\n",
    "print ('Train inputs shape: ', x_train.shape, 'Train targets shape', y_train.shape)\n",
    "\n",
    "# Check the shape of the test inputs and targets\n",
    "print ('Test inputs shape: ', x_test.shape, 'Test targets shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 4. Logistic regression with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 5. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a logistic regression object\n",
    "reg = LogisticRegression()\n",
    "\n",
    "# Fit The train inputs that is basically the whole training part of the machine learning\n",
    "reg.fit(x_train,y_train)\n",
    "\n",
    "# Assess the train accuracy of the model\n",
    "round(reg.score(x_train,y_train), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Accuracy Check (Details)\n",
    "> I re-check the accuracy by comparing the outputs and the true targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model outputs according to the LogReg model\n",
    "model_outputs = reg.predict(x_train)\n",
    "\n",
    "# True Targets \n",
    "true_targets = y_train \n",
    "\n",
    "# find out in how many instances we predicted correctly\n",
    "np.sum((model_outputs==true_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The total number of instances\n",
    "model_outputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy of the model\n",
    "accuracy = np.sum((model_outputs==y_train)) / model_outputs.shape[0]\n",
    "round(accuracy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Intercept and Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.68800249])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The intercept (a.k.a bias) of the model\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.90600225,  0.7548816 ,  3.08731323,  0.94700556,  0.02451849,\n",
       "         0.65563825, -0.25286853,  0.25704553, -0.25145264,  0.40171316,\n",
       "        -0.2957514 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The coefficients (a.k.a. weights) of the model\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The names of the columns\n",
    "unscaled_inputs.columns.values\n",
    "\n",
    "# Save the names of the columns in an ad-hoc variable\n",
    "feature_name = unscaled_inputs.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To summarize the results, I created a dataframe, then used the coefficients from the table. The model coefficients (model.coef_) should be transposted before throwing throws them into a df (a vertical organization, so that they can be multiplied by certain matrices later). Finally, I added the coefficient values to the summary table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.688002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.906002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.754882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>3.087313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.947006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.024518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.655638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.252869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.257046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.251453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.401713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pet</td>\n",
       "      <td>-0.295751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient\n",
       "0                Intercept    -1.688002\n",
       "1                 Reason_1     2.906002\n",
       "2                 Reason_2     0.754882\n",
       "3                 Reason_3     3.087313\n",
       "4                 Reason_4     0.947006\n",
       "5              Month Value     0.024518\n",
       "6   Transportation Expense     0.655638\n",
       "7                      Age    -0.252869\n",
       "8          Body Mass Index     0.257046\n",
       "9                Education    -0.251453\n",
       "10                Children     0.401713\n",
       "11                     Pet    -0.295751"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = pd.DataFrame (columns=['Feature name'], data = feature_name)\n",
    "# Add coefficients \n",
    "summary_table['Coefficient'] = np.transpose(reg.coef_)\n",
    "\n",
    "# Add the intercept \n",
    "summary_table.index = summary_table.index + 1  # Move all indices by 1\n",
    "# Add the intercept at index 0\n",
    "summary_table.loc[0] = ['Intercept', reg.intercept_[0]]\n",
    "\n",
    "# Sort the df by index\n",
    "summary_table = summary_table.sort_index()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretion of the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature name</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reason_3</td>\n",
       "      <td>3.087313</td>\n",
       "      <td>21.918110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reason_1</td>\n",
       "      <td>2.906002</td>\n",
       "      <td>18.283559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reason_4</td>\n",
       "      <td>0.947006</td>\n",
       "      <td>2.577978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reason_2</td>\n",
       "      <td>0.754882</td>\n",
       "      <td>2.127360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transportation Expense</td>\n",
       "      <td>0.655638</td>\n",
       "      <td>1.926372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Children</td>\n",
       "      <td>0.401713</td>\n",
       "      <td>1.494383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Body Mass Index</td>\n",
       "      <td>0.257046</td>\n",
       "      <td>1.293104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Month Value</td>\n",
       "      <td>0.024518</td>\n",
       "      <td>1.024822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Education</td>\n",
       "      <td>-0.251453</td>\n",
       "      <td>0.777670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.252869</td>\n",
       "      <td>0.776570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pet</td>\n",
       "      <td>-0.295751</td>\n",
       "      <td>0.743972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.688002</td>\n",
       "      <td>0.184888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Feature name  Coefficient  Odds_ratio\n",
       "3                 Reason_3     3.087313   21.918110\n",
       "1                 Reason_1     2.906002   18.283559\n",
       "4                 Reason_4     0.947006    2.577978\n",
       "2                 Reason_2     0.754882    2.127360\n",
       "6   Transportation Expense     0.655638    1.926372\n",
       "10                Children     0.401713    1.494383\n",
       "8          Body Mass Index     0.257046    1.293104\n",
       "5              Month Value     0.024518    1.024822\n",
       "9                Education    -0.251453    0.777670\n",
       "7                      Age    -0.252869    0.776570\n",
       "11                     Pet    -0.295751    0.743972\n",
       "0                Intercept    -1.688002    0.184888"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 'Odds ratio' of each feature\n",
    "summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)\n",
    "\n",
    "# Sort the table according to odds ratio\n",
    "summary_table.sort_values('Odds_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interpretation of the coefficients:** The closer the weights (coefficients) to 0, their odds ratios become smaller. Standardized coefficients are basically the coefficients of a regression, where all the variables have been standardized. One advantage of standardization is the standardized weights allow for a simple & straight forward to understand comparison between the variables. Thus whichever weights are larger, its corresponding features is more important to the target. Note that when the dummy variables are standardized, we lose the whole interpretability of a dummy.\n",
    "\n",
    "> In the Logistic Regression, the coefficients are predicting 'log odds'. From the table, it can be interpretated that when a feature is not particularly important to the targets, the coefficient of a feature is close to 0 and also, its odd ratio is also very close to 1. This is because a weight (i.e. coefficient) of 0 implies that no matter the feature value is, the value is multiplied by 0. In addition, for a unit change in the standardized feature, the odds increase by a multiple equal to the odds ratios. Thus, if the odd ratio is 1, it means there is no changes. <br>\n",
    "> Thus, given all features, these features seem to be the ones that make no difference. Thus we can drop them. \n",
    "\n",
    "> **4 reasons for Absent**: Reason_0 is dropped when dummy variables are created. To recall, Reason_0 represents a situation, where a person was absent, but no particular reasons were given. Therefore, the base model is when there is no reason for absenteeism. To be specific, I can conclude that it seems wherever a person has stated any reasons, we have a  much higher chance of getting excessive absence. \n",
    "\n",
    ">- **Reason_0**: Baseline\n",
    ">- **Reason_1**: Various Dieases \n",
    ">- **Reason_3**: Poisoning \n",
    ">- **Reason_2**: Pregnancy/ Giving Birth\n",
    ">- **Reason_4**: Light Dieases\n",
    "\n",
    "> A person who has reported the Reason_1 is 14 times more likely to be excessively absent than the Reason_0 (a person who didn't specify a reason). I particularly focused on the Reason_2 (Pregnancy & Giving birth). It is a prominent cause of absenteeism, but at the same time, it is the way less pronounced than Reason_1 or Reason_3.\n",
    "\n",
    "> Main drawback of standardisation comes when we deal with non-dummy standardised variables. For example, according to the table, the odd ratio of transportation expense is about 1.86. Its odds ratio implies that for 1 standardized unit increases in transportation expense, it is close to twice as likely to be excessively absent. This interpretation is hardly understandable. \n",
    "\n",
    "\n",
    "> Standardization models (almost) always yield higher accuracy, because the optimisation algorithms work better in this way. However depending which position I work, the preference of accuracy could be different. This it makes sense to create two versions of models one with standardisation features and one without them. Then try to draw insights from both. Since I predict values later, I prefer higher accuracy rate at least throughout the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Interpretation of a negative coefficient (feature: pet)**: For each additional standardised unit of pet, the odds are 1 0.7608 = 24% lower than the base model (no pet). I can interpret the result that if a person has more than a single pet, the person is probably not taking cate of the pets by himself, maybe someone else. \n",
    "\n",
    "> **Interpretation of the Intercept**: Intercept is used to get more accurate predictions but there is no specific meaning attached to it. In general, in machine learning, the intercept or the Bise calibrate the model. Without an intercept each prediction would be off the mark by precisely that value. \n",
    "\n",
    "> **Backward Elimination**: Backward elimination is one method to simplify the model. The idea is that we can simplify the model by excluding the features which have close to no contribution to the model. This indicates if these variables are removed, the rest of the model should not really change in terms of coefficient values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 6. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess the test accuracy of the model\n",
    "round(reg.score(x_test,y_test), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on the data that the model has never seen before, in 75% of the cases the model will predict correctly, if the person is going to be excessively absent. Often the test accuracy is 10-20% lower than the train accuracy. This indicate an overfitting. The model learned the train data very well, but it is prone to fail in real life. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82382633, 0.17617367],\n",
       "       [0.86071363, 0.13928637],\n",
       "       [0.79418937, 0.20581063],\n",
       "       [0.58674649, 0.41325351],\n",
       "       [0.59047288, 0.40952712],\n",
       "       [0.0784706 , 0.9215294 ],\n",
       "       [0.67472738, 0.32527262],\n",
       "       [0.37480563, 0.62519437],\n",
       "       [0.72183578, 0.27816422],\n",
       "       [0.75625756, 0.24374244],\n",
       "       [0.86419682, 0.13580318],\n",
       "       [0.69223869, 0.30776131],\n",
       "       [0.25934972, 0.74065028],\n",
       "       [0.46136628, 0.53863372],\n",
       "       [0.71570213, 0.28429787],\n",
       "       [0.47841848, 0.52158152],\n",
       "       [0.89102932, 0.10897068],\n",
       "       [0.22758282, 0.77241718],\n",
       "       [0.85983121, 0.14016879],\n",
       "       [0.59755422, 0.40244578],\n",
       "       [0.70535717, 0.29464283],\n",
       "       [0.7576082 , 0.2423918 ],\n",
       "       [0.7096897 , 0.2903103 ],\n",
       "       [0.70154218, 0.29845782],\n",
       "       [0.86673748, 0.13326252],\n",
       "       [0.16895155, 0.83104845],\n",
       "       [0.59755422, 0.40244578],\n",
       "       [0.60012512, 0.39987488],\n",
       "       [0.76295969, 0.23704031],\n",
       "       [0.59931834, 0.40068166],\n",
       "       [0.87634513, 0.12365487],\n",
       "       [0.87066806, 0.12933194],\n",
       "       [0.3817113 , 0.6182887 ],\n",
       "       [0.45771982, 0.54228018],\n",
       "       [0.71420608, 0.28579392],\n",
       "       [0.34902828, 0.65097172],\n",
       "       [0.70665547, 0.29334453],\n",
       "       [0.87066806, 0.12933194],\n",
       "       [0.15030829, 0.84969171],\n",
       "       [0.7911337 , 0.2088663 ],\n",
       "       [0.47475604, 0.52524396],\n",
       "       [0.75895374, 0.24104626],\n",
       "       [0.37137162, 0.62862838],\n",
       "       [0.86676079, 0.13323921],\n",
       "       [0.76822918, 0.23177082],\n",
       "       [0.26196987, 0.73803013],\n",
       "       [0.22587561, 0.77412439],\n",
       "       [0.1227009 , 0.8772991 ],\n",
       "       [0.70360277, 0.29639723],\n",
       "       [0.86591072, 0.13408928],\n",
       "       [0.75625756, 0.24374244],\n",
       "       [0.70206954, 0.29793046],\n",
       "       [0.59047288, 0.40952712],\n",
       "       [0.06705177, 0.93294823],\n",
       "       [0.86900577, 0.13099423],\n",
       "       [0.76822918, 0.23177082],\n",
       "       [0.02433552, 0.97566448],\n",
       "       [0.71420608, 0.28579392],\n",
       "       [0.12817218, 0.87182782],\n",
       "       [0.76945554, 0.23054446],\n",
       "       [0.4135329 , 0.5864671 ],\n",
       "       [0.87149245, 0.12850755],\n",
       "       [0.50531541, 0.49468459],\n",
       "       [0.36624496, 0.63375504],\n",
       "       [0.86419682, 0.13580318],\n",
       "       [0.59659667, 0.40340333],\n",
       "       [0.30745494, 0.69254506],\n",
       "       [0.9437163 , 0.0562837 ],\n",
       "       [0.71719346, 0.28280654],\n",
       "       [0.48753347, 0.51246653],\n",
       "       [0.76560471, 0.23439529],\n",
       "       [0.76295969, 0.23704031],\n",
       "       [0.30092054, 0.69907946],\n",
       "       [0.7127053 , 0.2872947 ],\n",
       "       [0.8684242 , 0.1315758 ],\n",
       "       [0.34902828, 0.65097172],\n",
       "       [0.59047288, 0.40952712],\n",
       "       [0.7695337 , 0.2304663 ],\n",
       "       [0.70665547, 0.29334453],\n",
       "       [0.56244588, 0.43755412],\n",
       "       [0.0784706 , 0.9215294 ],\n",
       "       [0.11239392, 0.88760608],\n",
       "       [0.87312779, 0.12687221],\n",
       "       [0.76029417, 0.23970583],\n",
       "       [0.87634513, 0.12365487],\n",
       "       [0.28280084, 0.71719916],\n",
       "       [0.76029417, 0.23970583],\n",
       "       [0.10775889, 0.89224111],\n",
       "       [0.27315503, 0.72684497],\n",
       "       [0.70360277, 0.29639723],\n",
       "       [0.79538669, 0.20461331],\n",
       "       [0.4437175 , 0.5562825 ],\n",
       "       [0.70535717, 0.29464283],\n",
       "       [0.70665547, 0.29334453],\n",
       "       [0.57242284, 0.42757716],\n",
       "       [0.15030829, 0.84969171],\n",
       "       [0.49798199, 0.50201801],\n",
       "       [0.06320928, 0.93679072],\n",
       "       [0.33167162, 0.66832838],\n",
       "       [0.26076232, 0.73923768],\n",
       "       [0.75189367, 0.24810633],\n",
       "       [0.34569985, 0.65430015],\n",
       "       [0.76822918, 0.23177082],\n",
       "       [0.24960159, 0.75039841],\n",
       "       [0.85894412, 0.14105588],\n",
       "       [0.37825229, 0.62174771],\n",
       "       [0.17102304, 0.82897696],\n",
       "       [0.78376213, 0.21623787],\n",
       "       [0.8684242 , 0.1315758 ],\n",
       "       [0.33598705, 0.66401295],\n",
       "       [0.36965944, 0.63034056],\n",
       "       [0.3425694 , 0.6574306 ],\n",
       "       [0.46684362, 0.53315638],\n",
       "       [0.70613282, 0.29386718],\n",
       "       [0.24939823, 0.75060177],\n",
       "       [0.46196141, 0.53803859],\n",
       "       [0.70460719, 0.29539281],\n",
       "       [0.08007801, 0.91992199],\n",
       "       [0.57780429, 0.42219571],\n",
       "       [0.12203021, 0.87796979],\n",
       "       [0.76162949, 0.23837051],\n",
       "       [0.23944377, 0.76055623],\n",
       "       [0.22716181, 0.77283819],\n",
       "       [0.25773427, 0.74226573],\n",
       "       [0.25168189, 0.74831811],\n",
       "       [0.73193969, 0.26806031],\n",
       "       [0.76822918, 0.23177082],\n",
       "       [0.75052168, 0.24947832],\n",
       "       [0.31850351, 0.68149649],\n",
       "       [0.87149245, 0.12850755],\n",
       "       [0.70053176, 0.29946824],\n",
       "       [0.82168529, 0.17831471],\n",
       "       [0.21952215, 0.78047785],\n",
       "       [0.49431172, 0.50568828],\n",
       "       [0.70360277, 0.29639723],\n",
       "       [0.06452596, 0.93547404],\n",
       "       [0.47470571, 0.52529429],\n",
       "       [0.3294678 , 0.6705322 ],\n",
       "       [0.59401844, 0.40598156],\n",
       "       [0.86816784, 0.13183216]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the predicted probabilities of each class\n",
    "# The first column shows the probability of a particular observation to be 0, while the second one - to be 1\n",
    "predicted_proba = reg.predict_proba(x_test)\n",
    "\n",
    "predicted_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17617367, 0.13928637, 0.20581063, 0.41325351, 0.40952712,\n",
       "       0.9215294 , 0.32527262, 0.62519437, 0.27816422, 0.24374244,\n",
       "       0.13580318, 0.30776131, 0.74065028, 0.53863372, 0.28429787,\n",
       "       0.52158152, 0.10897068, 0.77241718, 0.14016879, 0.40244578,\n",
       "       0.29464283, 0.2423918 , 0.2903103 , 0.29845782, 0.13326252,\n",
       "       0.83104845, 0.40244578, 0.39987488, 0.23704031, 0.40068166,\n",
       "       0.12365487, 0.12933194, 0.6182887 , 0.54228018, 0.28579392,\n",
       "       0.65097172, 0.29334453, 0.12933194, 0.84969171, 0.2088663 ,\n",
       "       0.52524396, 0.24104626, 0.62862838, 0.13323921, 0.23177082,\n",
       "       0.73803013, 0.77412439, 0.8772991 , 0.29639723, 0.13408928,\n",
       "       0.24374244, 0.29793046, 0.40952712, 0.93294823, 0.13099423,\n",
       "       0.23177082, 0.97566448, 0.28579392, 0.87182782, 0.23054446,\n",
       "       0.5864671 , 0.12850755, 0.49468459, 0.63375504, 0.13580318,\n",
       "       0.40340333, 0.69254506, 0.0562837 , 0.28280654, 0.51246653,\n",
       "       0.23439529, 0.23704031, 0.69907946, 0.2872947 , 0.1315758 ,\n",
       "       0.65097172, 0.40952712, 0.2304663 , 0.29334453, 0.43755412,\n",
       "       0.9215294 , 0.88760608, 0.12687221, 0.23970583, 0.12365487,\n",
       "       0.71719916, 0.23970583, 0.89224111, 0.72684497, 0.29639723,\n",
       "       0.20461331, 0.5562825 , 0.29464283, 0.29334453, 0.42757716,\n",
       "       0.84969171, 0.50201801, 0.93679072, 0.66832838, 0.73923768,\n",
       "       0.24810633, 0.65430015, 0.23177082, 0.75039841, 0.14105588,\n",
       "       0.62174771, 0.82897696, 0.21623787, 0.1315758 , 0.66401295,\n",
       "       0.63034056, 0.6574306 , 0.53315638, 0.29386718, 0.75060177,\n",
       "       0.53803859, 0.29539281, 0.91992199, 0.42219571, 0.87796979,\n",
       "       0.23837051, 0.76055623, 0.77283819, 0.74226573, 0.74831811,\n",
       "       0.26806031, 0.23177082, 0.24947832, 0.68149649, 0.12850755,\n",
       "       0.29946824, 0.17831471, 0.78047785, 0.50568828, 0.29639723,\n",
       "       0.93547404, 0.52529429, 0.6705322 , 0.40598156, 0.13183216])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select ONLY the probabilities referring to 1s\n",
    "predicted_proba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant module\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model file\n",
    "with open('model', 'wb') as file:\n",
    "    pickle.dump(reg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the scaler file\n",
    "with open('scaler','wb') as file:\n",
    "    pickle.dump(absenteeism_scaler, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
